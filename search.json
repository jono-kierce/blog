[
  {
    "objectID": "posts.html",
    "href": "posts.html",
    "title": "Posts",
    "section": "",
    "text": "Expected Wins Analysis in Fantasy Basketball Using the ESPN API\n\n\n\nESPN Fantasy\n\nstatistical analysis\n\n\n\n\n\n\n\n\n\nJan 21, 2026\n\n\nJonathan Kierce\n\n\n\n\n\n\n\n\n\n\n\n\nInitial Hardware Setup\n\n\n\ngym-project\n\n\n\n\n\n\n\n\n\nJan 15, 2026\n\n\nJonathan Kierce\n\n\n\n\n\n\n\n\n\n\n\n\nAn Idea, or two\n\n\n\ngym project\n\ncomputer vision\n\n\n\n\n\n\n\n\n\nJan 13, 2026\n\n\nJonathan Kierce\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to Remote Photoplethysmography (rPPG)\n\n\n\nrPPG\n\n\n\n\n\n\n\n\n\nDec 12, 2025\n\n\nJonathan Kierce\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "My Blog",
    "section": "",
    "text": "Welcome to my blog. I will pop random side quests I’m completing here. Here are my latest posts:\n\n\n\n\n\n\n\n\n\n\n\n\nExpected Wins Analysis in Fantasy Basketball Using the ESPN API\n\n\n\nESPN Fantasy\n\nstatistical analysis\n\n\n\n\n\n\n\nJan 21, 2026\n\n\n\n\n\n\n\n\n\n\n\nInitial Hardware Setup\n\n\n\ngym-project\n\n\n\n\n\n\n\nJan 15, 2026\n\n\n\n\n\n\n\n\n\n\n\nAn Idea, or two\n\n\n\ngym project\n\ncomputer vision\n\n\n\n\n\n\n\nJan 13, 2026\n\n\n\n\n\n\n\n\n\n\n\nIntroduction to Remote Photoplethysmography (rPPG)\n\n\n\nrPPG\n\n\n\n\n\n\n\nDec 12, 2025\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/04-espn-expectedwins.html",
    "href": "posts/04-espn-expectedwins.html",
    "title": "Expected Wins Analysis in Fantasy Basketball Using the ESPN API",
    "section": "",
    "text": "My friends and I participate each year in a fantasy ESPN league. Invariably, there are always a few that complain of how unlucky they were in scheduling, and that there were teams that were worse that made finals/finished higher/didn’t come last instead.\nThere is (some) merit to these complaints. Because matchups are head-to-head, your record depends partly on who you played, not just how many points you scored. Each week 2 teams are matched and the team with the higher score wins. Therefore it is possible to have the 2nd highest score of the week, and lose to the highest scorer. Similarly, it is possible to have the 2nd lowest score of the week and still win because you are playing the lowest scorer that week.\nWhile the Points For and Points Against metrics are often pointed to as a way of measuring how ‘unlucky’ you have been with the schedule, this doesn’t exactly reflect how good your team is. For example, if you were really good for the first half of the year, but then had a bunch of injuries, you may have won more games than someone who has the same amount of Points For but was just consistently bad."
  },
  {
    "objectID": "posts/04-espn-expectedwins.html#references",
    "href": "posts/04-espn-expectedwins.html#references",
    "title": "Expected Wins Analysis in Fantasy Basketball Using the ESPN API",
    "section": "References",
    "text": "References\n\n\nWendt, Christian. 2025. “Espn-Api: ESPN Fantasy API (Football, Basketball).” https://github.com/cwendt94/espn-api."
  },
  {
    "objectID": "posts/01-firstpost.html",
    "href": "posts/01-firstpost.html",
    "title": "An Idea, or two",
    "section": "",
    "text": "A quick welcome to my blog. I had this idea a while ago, to create a blog to show personal projects and the like now that I’ve graduated university. To be honest, I’m not sure of my target audience, if there is one, but I’m hopeful that having this will motivate me to a) complete personal projects and b) complete them more stringently.\nNow that was one idea. The idea I want to talk about here is a project idea. Those that know me know that these last few months I’ve been building a small basement gym (I’ve been quite gym-obsessed these last ~2 years).\nI was looking at our setup - squat rack in particular - and it struck me how this could be a fantastic computer vision problem. So, my idea is to build a camera-based system that can sit in the basement, pointed at the squat rack, and track:\n\nExercise type\nI.e squat, bench press, shoulder press etc.\nNumber of repitions\nThe number of times each exercise has been performed\nWeight\nThe weight on the barbell\n\nThis should be possible, especially for our setup. It is particularly advantageous as we have a bright red barbell and bright rubber weight plates of different colours corresponding to their weights, which should make it possible to differentiate them via camera.\n\n\n\nOur Squat Rack Setup\n\n\nThe exercise type could be classified based off a pre-existing landmark, which detects specific landmarks of the body, and then passed through a fairly lightweight machine learning model, such as a small CNN. Starting with just a squat, deadlift or bench press, it should be simple enough to classify between these exercises, and we can extend further once we have completed that. Finally, the number of repitions could be calculated by tracking the height of the barbell, passing through a smoothing filter to remove noise in detection / camera and then counting significant peaks.\nI am thinking about running this on a Raspberry Pi 5. I’m not sure exactly what I’ll do with this data once collected- it could be sent to a Google Sheets, to track everything. Something else that would be cool would be having a screen there showing the data from the completed set, so when you’ve repped out a set of max squats and have blurry vision you’re not left wondering if you made 7 or 8 on that last set."
  },
  {
    "objectID": "posts/02-rppgintro.html",
    "href": "posts/02-rppgintro.html",
    "title": "Introduction to Remote Photoplethysmography (rPPG)",
    "section": "",
    "text": "Over the past year, as part of my Bachelor of Engineering, I’ve been working on a remote photoplethysmography project, with specific contributions of creating an iOS application, and of extending this work into Atrial Fibrillation (AF) detection. I thought it might be interesting to write about rPPG from a few perspectives. This post is a quick crash course collating the general state-of-the-field as discovered while researching this project."
  },
  {
    "objectID": "posts/02-rppgintro.html#references",
    "href": "posts/02-rppgintro.html#references",
    "title": "Introduction to Remote Photoplethysmography (rPPG)",
    "section": "References",
    "text": "References\n\n\nBoccignone, Giuseppe, Donatello Conte, Vittorio Cuculo, Alessandro D’Amelio, Giuliano Grossi, and Raffaella Lanzarotti. 2020. “An Open Framework for Remote-PPG Methods and Their Assessment.” IEEE Access 8: 216083–103. https://doi.org/10.1109/ACCESS.2020.3040936.\n\n\nDzedzickis, Andrius, Arturas Kaklauskas, and Vytautas Bučinskas. 2020. “Human Emotion Recognition: Review of Sensors and Methods.” Sensors 20 (January): 592. https://doi.org/10.3390/s20030592.\n\n\nHaan, Gerard de, and Vincent Jeanne. 2013. “Robust Pulse Rate from Chrominance-Based rPPG.” IEEE Transactions on Biomedical Engineering 60 (10): 2878–86. https://doi.org/10.1109/TBME.2013.2266196.\n\n\nHaugg, Fridolin, Mohamed Elgendi, and Carlo Menon. 2022. “Effectiveness of Remote PPG Construction Methods: A Preliminary Analysis.” Bioengineering 9 (10): 485. https://doi.org/10.3390/bioengineering9100485.\n\n\nKim, Dae-Yeol, Kwangkee Lee, and Chae-Bong Sohn. 2021. “Assessment of ROI Selection for Facial Video-Based rPPG.” Sensors 21 (23). https://doi.org/10.3390/s21237923.\n\n\nKing, Davis E. 2015. “Shape_predictor_68_face_landmarks.dat.bz2.” Dlib model file download. http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2.\n\n\nMakowski, Dominique, Tam Pham, Zen J. Lau, Jan C. Brammer, François Lespinasse, Hung Pham, Christopher Schölzel, and S. H. Annabel Chen. 2021. “NeuroKit2: A Python Toolbox for Neurophysiological Signal Processing.” Behavior Research Methods 53 (4): 1689–96. https://doi.org/10.3758/s13428-020-01516-y.\n\n\nVerkruysse, Wim, Lars O. Svaasand, and J. Stuart Nelson. 2008. “Remote Plethysmographic Imaging Using Ambient Light.” Optics Express 16 (26): 21434–45. https://doi.org/10.1364/OE.16.021434.\n\n\nYang, Yuting, Chenbin Liu, Hui Yu, Dangdang Shao, Francis Tsow, and Nongjian Tao. 2016. “Motion Robust Remote Photoplethysmography in CIELab Color Space.” Journal of Biomedical Optics 21 (11): 117001. https://doi.org/10.1117/1.JBO.21.11.117001."
  },
  {
    "objectID": "posts/03-rasppi-setup.html",
    "href": "posts/03-rasppi-setup.html",
    "title": "Initial Hardware Setup",
    "section": "",
    "text": "Today I received the parcel with my hardware, meaning it’s time to stop talking about this project and start doing!\nI elected for a Raspberry Pi 5. I set it up according to this guide."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  }
]